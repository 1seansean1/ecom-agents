# Morphogenetic Agency (v5)
## Failure‚ÄëTriggered Multiscale Active Inference with Assembly‚ÄëCached Competencies

**One‚Äëline compression:** *Feasibility‚Äëconstrained, CP‚Äëprofiled multiscale active inference with assembly‚Äëcached competencies.*

---

## Abstract

This document gives a **measurement‚Äëfirst** synthesis of six ideas: **Assembly Theory** (construction cost with reuse), **Cognitive Light Cones** (goal reach), **Causal Emergence** (which scales have causal grip), **Markov blankets** (agent boundaries), **active inference** (goal‚Äëdirected dynamics + exploration), and **Informational Monism** (how partitions become measurable symbols with capacities and costs). The central claim is a design pattern: **agents grow by failing**. A goal is treated as an **attractor basin** at a causally relevant, operationally feasible scale. When empirical goal failure exceeds tolerance, the agent enters a **structured morphogenetic search** (APS) that escalates from parameter tuning, to partition/goal retargeting, to boundary (blanket) expansion, to multiscale re‚Äëorganization ‚Äî ordered by assembly cost because each successive tier modifies progressively more of the agent's substrate. Successful solutions are **cached as reusable subassemblies** (modules/priors/codebooks/blanket levels), with cached competencies ordered from parameter‚Äëlevel (sensitization, habituation) through partition‚Äëlevel (associative learning) to substrate‚Äëlevel (anatomical homeostasis). The engineered analogue of Assembly Theory's "copy number" is **reuse frequency** of cached subassemblies. Over development, the framework predicts stepwise growth in the agent's feasible goal set (CLC expansion), broadening of causal contribution across scales (CE 2.0 profile), and rising informational efficiency **Œ∑ = C(P)/W**. The last section specifies an instrumentation suite sufficient to falsify the bridge hypotheses that connect these frameworks.

---

## Scope and stance

This is not a claim that cells literally compute free‚Äëenergy gradients. It is:

- **Descriptive** for biology: Markov‚Äëblanket/active‚Äëinference language is a redescription that is useful when it yields testable predictions or engineering control handles.
- **Prescriptive** for engineered agents: we can explicitly build systems that minimize (expected) free energy and implement the exploration cascade described here.

The word **morphogenetic** is used deliberately: the framework treats agent development as analogous to biological morphogenesis ‚Äî goal‚Äëdirected construction of form under resource constraints, where "form" includes computational architecture, interface structure, and compositional hierarchy, not only physical shape. The planaria results in Proposition 3 are not mere analogy; they are a biological instance of the same abstract pattern (failure‚Äëtriggered basin switching in a multistable attractor landscape) that the framework prescribes for engineered systems.

---

## Claim stack (what the argument must deliver)

1. **Bounded feasibility:** Structural resources constrain what kinds of goal horizons, observation complexities, and tolerances are feasible.
2. **Scale relevance:** Only some coarse‚Äëgrainings are operationally realizable by the agent; among those, causal contribution is distributed across scales.
3. **Goals as basins:** Goal specifications correspond to attractor basins at causally relevant scales.
4. **Boundaries matter:** Markov blankets define what partitions and interventions are feasible at each scale.
5. **Failure drives search:** Goal failure beyond tolerance triggers a structured search over parameters, partitions, boundaries, and scale organization ‚Äî ordered by substrate modification cost.
6. **Success caches:** Successful solutions become reusable subassemblies with an ordered competency taxonomy; repeated reuse is the selection‚Äësignature analogue for engineered systems.
7. **Measurable signature:** The combined system has observable developmental trajectories.

---

## Notation (minimal)

| Symbol | Meaning |
|---|---|
| x | external states |
| Œº | internal states (belief/latent states) |
| s | sensory states |
| a | active states |
| b = (s,a) | Markov blanket separating Œº from x |
| œÄ | a partition / coarse‚Äëgraining map |
| œÉ | symbols (macrostates) produced by œÄ |
| Œ∏ | agent configuration (architecture + parameters + stored caches) |
| F | variational free energy |
| ùîº[F] | expected free energy (EFE) |
| AI(Œ∏) | assembly index (structural construction cost with reuse) |
| CLC(Œ∏) | cognitive light cone (goal reach ‚Äî spatiotemporal extent) |
| EI, CP(l) | effective information / causal power profile across scales |
| Œ∑(Œ∏) | informational efficiency (recoverable bits per unit work) |

---

## Core definitions (operational, not rhetorical)

### Informational Monism objects (measurement first)

- A **partition** œÄ maps physical microstates to symbols: œÄ : X_phys ‚Üí Œ£.
- A symbol is **(T,Œµ)-recoverable** if it can be stably decoded through the agent's interface over horizon T with error ‚â§ Œµ.
- A partition + dynamics induces a **macro‚Äëchannel** P(œÉ_out | œÉ_in, u) where u summarizes allowed interventions/controls.
- **Channel capacity** C(P) is the maximum mutual information achievable over that induced macro‚Äëchannel (given the admissibility constraints).
- **Informational efficiency** is:

$$\eta(\theta) := \frac{C(P_\theta)}{W(\theta)}$$

where W is the work/energy (or a calibrated proxy like Joules, wall‚Äëclock time, or FLOP‚Äëenergy) required to realize P_Œ∏ over the evaluation horizon.

### Goal Measurement Formalism (turning "purpose" into a test)

- **G‚Å∞ (preference):** informal orientation / value signal. In biology: bioelectric prepattern encoding morphological target. In engineering: requirements‚Äëlevel intent prior to formalization.
- **G¬π (spec):** a measurable goal tuple G¬π = (F_G, Œµ_G, T, m_G), where:
  - F_G is a failure predicate on observed variables,
  - Œµ_G is tolerated failure probability,
  - T is the evaluation horizon,
  - m_G is the observation map (what variables count as "goal state").
- **G¬≤ (implementation):** the realized policy/dynamics that attempts to satisfy G¬π.
- The **specification gap** ‚ÄñG¬π ‚àí G¬≤‚Äñ is any metric of mismatch sufficient to predict persistent failure.
- The **formalization gap** (G‚Å∞ ‚Üí G¬π) captures how well the informal preference has been translated into a testable specification. This gap is relevant at Tier 1 of the APS cascade, where "retargeting" sometimes means refining G‚Å∞ ‚Üí G¬π (formalizing a previously vague preference), not just switching between existing G¬π specs.

### Assembly Theory objects (what "caching" means structurally)

- **AI(Œ∏):** minimum number of join operations to construct Œ∏ allowing reuse of subassemblies.
- **Selection signature (AT):** high AI with high copy number indicates selection.
  **Engineered analogue:** high structural complexity with high reuse frequency indicates functional selection/retention.

> **AT controversy note:** Assembly measures have been criticized as repackaging existing complexity notions. This framework does not require AI to be a fundamentally new information measure. We use AI as a *structural proxy* for (i) internal degrees of freedom, (ii) modular reuse, and (iii) feasible interface complexity. Any monotone structural complexity measure that tracks reusable construction cost could play the same role.

### Causal Emergence objects (which scales "do the work")

- **Effective information (EI):** mutual information under **uniform** (max‚Äëentropy) interventions on causes:

$$EI = I(X_{\mathrm{do}};Y)= \sum_x p(\mathrm{do}(x))\, D_{KL}(P(Y|\mathrm{do}(x))\,\|\,P(Y))\quad\text{with}\quad p(\mathrm{do}(x))=\frac{1}{|X|}$$

The uniform intervention is load‚Äëbearing: it ensures fair cross‚Äëscale comparison by max‚Äëentropy probing.

- **CE 2.0 (Hoel 2025):** causation is generally **distributed**; causal contribution is represented by a profile {CP(l)} across scales l, not a single argmax scale. *Emergent complexity* measures how widely distributed causation is across the scale hierarchy.

### Markov blanket object (what is feasible)

- b=(s,a) is a Markov blanket if Œº ‚üÇ x | b.
  Operationally: s is the observation interface; a is the intervention interface.

---

## Bridge hypotheses (explicit assumptions)

These are the only places the argument "reaches across" frameworks.

**BH1 (Assembly ‚Üí representational/interface capacity, necessary not sufficient).**
Higher reusable structural complexity generally enables:
- more internal degrees of freedom (more possible Œº‚Äëstates),
- richer partitions œÄ that are recoverable at the interface,
- larger/cleaner sensory and active surfaces (higher effective bandwidth).

But AI is a static structural measure; CLC is a dynamic functional measure. High AI does not guarantee large CLC without appropriate *organization* (functional blanket hierarchies with correct coupling). A disassembled watch and an assembled watch may have similar AI but radically different CLC.

**BH2 (Capacity bounds light cone).**
For any agent, finite internal state capacity + finite interface bandwidth + finite energy budget imply an upper bound on the set of goal specs it can satisfy:
- longer horizons T require memory / model capacity,
- richer observation maps m_G require sensory bandwidth and stable partitions,
- tighter tolerances Œµ_G require more control precision and/or energy.

**BH3 (Nested organization tracks complexity).**
As reusable structure increases, additional nested Markov blankets become feasible (new compositional levels with their own s_l, a_l, Œº_l).

**BH4 (Caching increments reusable structure).**
Successful adaptations are stored in forms that reduce future search cost: codebooks, priors, modules, protocols, and (sometimes) new blanket levels. Repeated reuse is the analogue of high copy number. Cached competencies have an ordered taxonomy (see Proposition 7).

These hypotheses are falsifiable via the observable suite in "Instrumentation."

---

## Main argument (eight propositions)

### Proposition 1 ‚Äî Assembly constrains feasible agency (bounded feasibility)

**Claim.** AI(Œ∏) (or a structural proxy) is a necessary resource bound on feasible goal specifications and therefore on CLC(Œ∏).

**Reasoning.**
- If the induced macro‚Äëchannel P_Œ∏ cannot stably represent the variables required by m_G over horizon T with tolerance Œµ_G, then G¬π is infeasible regardless of "intent."
- Increasing reusable structure typically increases the size/quality of Œ£_stable(Œ∏) and the achievable C(P_Œ∏), expanding the set of feasible (T, m_G, Œµ_G).

**Deliverable.** A testable relation of the form:
- feasible goal set ùí¢(Œ∏) ‚äÜ ùí¢_max(AI(Œ∏)),
- CLC(Œ∏) := max_{G¬π‚ààùí¢(Œ∏)} (horizon(G¬π), dim(m_G(G¬π))).

CLC is a *spatiotemporal* measure following Levin: it captures both the temporal reach (horizon) and the spatial/dimensional complexity (observation map richness) of the largest feasible goal.

*(The functional form of ùí¢_max is an open problem; see "Open problems.")*

---

### Proposition 2 ‚Äî Feasible partitions + CE 2.0 pick operative scales

**Claim.** "Relevant scale" is: scales with significant causal contribution **among partitions the agent can actually implement**.

Define:
- **P_feasible(Œ∏):** partitions œÄ that are (i) admissible (interface‚Äëbounded, counterfactually robust, compositional) and (ii) operationally realizable at the blanket boundary (inferable from s and intervenable via a).
- Compute CE 2.0 causal profile {CP(l)} over feasible scales.

Then the operative set is:

$$S_{\mathrm{eff}}(\theta) = \{ l : CP(l) \geq \tau \text{ and } \pi_l \in P_{\mathrm{feasible}}(\theta) \}$$

> **Engineering approximation note.** CE 2.0 treats {CP(l)} as a continuous distribution; the threshold œÑ discretizes it. This is an engineering necessity ‚Äî resource allocation to scale‚Äëmonitoring requires discrete decisions about which scales to instrument. In principle, goal‚Äëspecification effort could be weighted proportional to CP(l) without a hard cutoff; in practice, œÑ trades off monitoring cost against causal coverage. The framework is robust to the choice of œÑ: tighter œÑ ‚Üí more scales monitored ‚Üí higher overhead; looser œÑ ‚Üí fewer scales ‚Üí risk of missing causally relevant dynamics.

**Implication.** Goal specs should choose observation maps m_G that project onto variables at scales in S_eff (possibly multiple scales if CP is distributed).

**Bridge use.** BH3 links rising reusable structure to deeper blanket hierarchies, which expands P_feasible(Œ∏) and can broaden {CP(l)}.

---

### Proposition 3 ‚Äî Goals are attractor basins at causally relevant scales

**Claim.** At causally relevant scales, the dynamics define attractors; a goal spec G¬π names a basin.

- Basins are defined over observed coordinates m_G(¬∑).
- Failure predicate F_G describes leaving the basin.
- Œµ_G sets tolerated escape probability; T sets evaluation horizon.
- Compound goals (e.g. "generate profit while not harming while staying alive") are intersected basins with priority‚Äëordered relaxation: under resource pressure, the lowest‚Äëpriority basin constraint is relaxed first.

**Biological instance (planaria ‚Äî not analogy, same abstract pattern).** Levin's experimental results demonstrate that the morphogenetic attractor landscape is:

- **Multistable:** brief pharmacological inhibition of gap junctional communication permanently rewrites the regenerative target from one‚Äëheaded to two‚Äëheaded (Durant et al. 2017). This is basin switching via bioelectric state manipulation, without genomic change.
- **Reversible:** restoring normal bioelectric state with pump‚Äëblocking reagents resets regeneration to one‚Äëheaded (Durant et al. 2017). The landscape has at least two stable basins accessible via the same control interface.
- **Phylogenetically deep:** gap junction uncoupling in *G. dorotocephala* produces head morphologies of species ~150 Mya divergent (*S. mediterranea*, *P. felina*) despite wild‚Äëtype genome (Emmons‚ÄëBell et al. 2015). The landscape encodes conserved alternative morphologies ‚Äî more basins than default expression reveals.

This is the morphogenetic instance of the framework's general claim: goal‚Äëdirected systems operate in multistable landscapes, and interventions at the right scale (here: bioelectric, not genomic) can switch between basins. The engineering prescription follows: design agents whose goal specifications correspond to identifiable, switchable basins at causally relevant scales.

**Goal Measurement Formalism link.** Each G¬π_i specifies a basin: F_{G_i} defines the basin boundary, Œµ_{G_i} is tolerated excursion probability, T_i is evaluation timescale, m_{G_i} projects onto goal‚Äërelevant coordinates. The specification gap ‚ÄñG¬π ‚àí G¬≤‚Äñ measures how far the implemented dynamics are from reliably occupying the specified basin.

---

### Proposition 4 ‚Äî Markov blankets define boundaries (and feasibility) at each scale

**Claim.** The Markov blanket b=(s,a) is the concrete implementation of "what the agent can measure and do."

- IM's interface‚Äëboundedness (C1) is the statement: partitions must live at the blanket boundary. The agent cannot partition states it cannot sense.
- Nested blankets imply nested feasible partition sets, enabling multiscale control without micromanaging microdynamics (boundary‚Äëcondition control / "bioprompting" in Levin's terminology).
- AI(Œ∏) constrains the depth of the blanket hierarchy: low AI ‚Üí shallow hierarchy ‚Üí few compositional levels ‚Üí narrow P_feasible.

**Bridge use.** BH3 links rising reusable structure to deeper blanket hierarchies, which expands P_feasible(Œ∏) and can broaden {CP(l)}.

---

### Proposition 5 ‚Äî Active inference supplies within‚Äëblanket dynamics and an exploration term

**Claim.** Within each blanket level l, dynamics can be implemented (engineering) or redescribed (biology) as minimizing variational free energy. Under the standard generative model p(s,x) = p(s|x)p(x):

$$F = -\ln p(s) + D_{KL}(q(x)\,\|\,p(x|s))$$

Since D_KL ‚â• 0, F upper‚Äëbounds surprise ‚àíln p(s). Perception (updating Œº) reduces the KL term; action (updating a) reduces surprise by changing sensory input.

Exploration pressure comes from **expected free energy** (EFE), which decomposes into:
- **Extrinsic value** (pragmatic): preference satisfaction / goal‚Äëseeking,
- **Epistemic value** (intrinsic): information gain / uncertainty reduction.

The epistemic term supplies exploration without hand‚Äëcoded randomness ‚Äî agents preferentially sample actions that reduce model uncertainty about the landscape.

**Engineering payoff.** This gives one optimization language for:
- state inference (update Œº ‚Üí reduce KL),
- control (update a ‚Üí reduce surprise),
- exploration (choose actions that maximize expected information gain).

**Shared priors compress communication.** When agents share a generative model (shared context K in IM terms), prediction errors decrease: H(I|K) < H(I). This reduces the free energy each agent must dissipate, directly reducing W_operate and increasing Œ∑. In morphogenesis: the bioelectric prepattern acts as K, biasing all cells toward the same attractor basin.

---

### Proposition 6 ‚Äî Goal failure triggers a structured morphogenetic search (APS)

**Trigger.** If UCB_{1‚àíŒ¥}(pÃÇ_fail(Œ∏; t)) > Œµ_G, enter exploration.

**APS cascade (ordered by substrate modification cost ‚Äî cheapest first).**

| Tier | Operation | What is modified | Why this ordering |
|---|---|---|---|
| **0: Parameter tuning** | Adjust Œº, a within current model | Nothing structural ‚Äî beliefs and actions only | Zero assembly cost; operates within existing landscape |
| **1: Goal/partition retargeting** | Change which basin is targeted; repartition œÄ_G; possibly refine G‚Å∞‚ÜíG¬π (formalize a vague preference) | The goal specification (a configuration artifact) | Low assembly cost; changes *which goal* is pursued, not *what the agent is* |
| **2: Boundary expansion** | Expand s or a, add protocols/modules, modify priors/codebooks | The agent's sensing/acting substrate | Medium assembly cost; changes the agent's *interface* ‚Äî what it can measure and do |
| **3: Scale reorganization** | Recompute {CP(l)}; add/remove blanket levels; redesign compositional hierarchy | The agent's scale structure | High assembly cost; reorganizes *how many levels of description* the agent operates across |

**Ordering justification.** Each tier modifies progressively more of the agent's substrate. Tier 0 changes parameters within a fixed architecture. Tier 1 changes the goal specification, which is a configuration artifact (analogous to changing a setpoint vs. rewiring the controller). Tier 2 changes the agent's boundary ‚Äî what it can sense and do ‚Äî which requires structural modification. Tier 3 reorganizes the compositional hierarchy itself, which is the most expensive because it may invalidate existing caches and require re‚Äëderiving the causal profile.

**Selection criterion.** Choose the candidate change that best trades off:
- expected reduction in failure probability / free energy,
- expected information gain (epistemic value from EFE),
- assembly cost / implementation cost.

**Diagnostic cascade.** At each tier, the agent answers a question before escalating:
- Tier 0: "Can I reach the basin with better parameters?" If no ‚Üí
- Tier 1: "Am I targeting the right basin? Is my G¬π well‚Äëspecified?" If wrong basin or vague G‚Å∞ ‚Üí
- Tier 2: "Do I need capabilities I don't have?" If yes ‚Üí
- Tier 3: "Is my scale structure correct for this problem?"

---

### Proposition 7 ‚Äî Successful solutions cache as reusable assembly (competency taxonomy)

**Claim.** When APS succeeds, the winning solution is stored in a form that reduces future expected search cost.

Track two quantities:
- **structural complexity proxy** (AI or module‚Äëgraph join cost),
- **reuse count** n_i (copy‚Äënumber analogue): how often a cached subassembly is invoked successfully across episodes/tasks.

**Competency taxonomy (ordered by assembly cost).** Following Levin's continuum of cognitive competencies, each cached adaptation type corresponds to a distinct landscape modification:

| Competency | Landscape modification | IM/Agentic analogue | Assembly cost (ordinal) |
|---|---|---|---|
| **Sensitization** | Lower basin barrier (easier to trigger response) | Reduce Œµ_G threshold for known failure mode | Lowest (parameter) |
| **Habituation** | Raise barrier for benign perturbation (harder to trigger) | Increase Œµ_G for benign fluctuations | Low (parameter) |
| **Associative learning** | Create saddle/channel connecting previously separate basins; context‚Üíresponse binding | Cache codebook K indexed by context fingerprint | Medium (new partition element) |
| **Anatomical homeostasis** | Create entirely new attractor basin actively maintained as setpoint | New G¬π with own (F_G, Œµ_G, T, m_G) and dedicated monitoring | High (new blanket level + attractor) |

The ordinal claim ‚Äî each successive type requires strictly more structural modification ‚Äî is defensible from the landscape descriptions. Specific integer ŒîAI values are not assigned because the mapping from cognitive competencies to join‚Äëcounts is not yet formally derived (see Open Problems).

These competency types map onto Levin's *persuadability continuum*: the most efficient protocol for interacting with a system progresses from direct physical manipulation ‚Üí reward/punishment ‚Üí symbolic communication ‚Üí linguistic goal‚Äësetting. Each step up the continuum implies a larger CLC and higher assembly.

**Prediction.** Reuse counts become heavy‚Äëtailed: a few caches dominate (high n_i), and those tend to be higher‚Äëcomplexity modules that enable larger CLC expansions.

---

### Proposition 8 ‚Äî The compound system has a measurable developmental signature

If Propositions 1‚Äì7 hold, then during development/training we expect:

1. **CLC expands stepwise** (new basins become reliably reachable; both horizon T and observation complexity dim(m_G) grow).
2. **P_feasible expands** (new partitions become recoverable/intervenable).
3. **CP(l) broadens** (causal contribution distributes across more scales).
4. **Œ∑ increases** (capacity per work rises as priors/caches compress communication).
5. **Œµ‚Äëtriggers decline in mastered regions** and remain nonzero at the frontier.
6. **Competency distribution shifts** from low‚Äëcost types (sensitization/habituation) toward high‚Äëcost types (associative learning/anatomical homeostasis) over developmental time.

---

## Instrumentation (how you would actually measure this)

| Observable | Practical estimator | What would count as support |
|---|---|---|
| AI‚Äëproxy(Œ∏) | Minimal join count of module DAG; number of reusable codebooks + compositional depth | Rises when new reusable modules appear |
| Reuse count n_i | Invocation count of cache i conditioned on success | Heavy‚Äëtailed; correlates with retained modules |
| CLC(Œ∏) | Max (T, dim(m_G)) pair with UCB(p_fail) ‚â§ Œµ_G for some goal family | Stepwise increases aligned with new modules |
| P_feasible | Count of partitions whose symbols are (T,Œµ)-recoverable and controllable | Increases with interface expansion |
| CP(l) profile | EI/causal contribution per scale from controlled interventions and confusion matrices | Broadens; shifts after Tier‚Äë3 events |
| Œ∑(Œ∏) | Estimated channel capacity / measured energy or time cost | Increases as caches reduce per‚Äëtask cost |
| APS tier usage | Logs of which tier was needed to restore success | Shifts to higher tiers at capability frontiers |
| Attractor count | Number of distinct G¬π simultaneously satisfied stably | Increases with growth |
| Spec gap ‚ÄñG¬π‚àíG¬≤‚Äñ | Regret: expected failure rate minus Œµ_G, estimated from holdout episodes with distribution shift | Shrinks within mastered domains; persists at frontier |
| Formalization gap | Fraction of active goals still at G‚Å∞ (no testable F_G) vs. formalized G¬π | G‚Å∞ fraction decreases over development |
| Competency distribution | Classify cached adaptations as sensitization / habituation / associative / homeostatic | Shifts from low‚Äëcost to high‚Äëcost types |

---

## Open problems (what must be derived or tested)

1. **Derive AI ‚Üí CLC bounds** via explicit information‚Äëtheoretic constraints (rate‚Äëdistortion / channel capacity / memory limits). The finite‚Äërepresentational‚Äëcapacity argument is sound but informal; a proper derivation should yield functional form for ùí¢_max.
2. **Thermodynamic grounding:** relate ŒîF or mutual information processed per episode to minimal work and to tier costs (Landauer‚Äëstyle floors). Each APS tier should have at least an order‚Äëof‚Äëmagnitude thermodynamic cost estimate.
3. **Operational CE 2.0 measurement:** robust estimators of CP(l) in partially observed, non‚Äëstationary systems.
4. **AT mapping in engineered systems:** principled AI proxies for software/modules and how reuse relates to "copy number."
5. **Pruning and re‚Äëorganization:** conditions under which AI‚Äëproxy is not monotone (compression, forgetting) while Œ∑ improves.
6. **Competency ‚Üí ŒîAI derivation:** formalize the mapping from landscape modifications (barrier lowering, basin linking, basin creation) to join‚Äëcount increments in the assembly space. This would convert ordinal cost rankings to cardinal measures.
7. **G‚Å∞ ‚Üí G¬π formalization dynamics:** under what conditions does the APS cascade refine preferences into specifications vs. simply switching between existing specs? This is the requirements‚Äëelicitation problem recast in morphogenetic terms.

---

## The argument in 18 lines (compressed)

1) Partitions œÄ create symbols œÉ; symbols exist only if recoverable.
2) Recoverable partitions + dynamics induce a macro‚Äëchannel P(œÉ_out|œÉ_in,u).
3) Capacity C(P) and cost W define efficiency Œ∑ = C(P)/W.
4) Markov blankets implement the interface that makes partitions/interventions feasible.
5) Feasible partitions P_feasible are those inferable from s and controllable via a.
6) EI quantifies causal content under uniform intervention; admissibility ensures EI > 0.
7) CE 2.0 yields a distributed causal profile {CP(l)} rather than a single best scale.
8) Goals must be specified on variables at scales with significant CP within P_feasible.
9) Goal specs G¬π=(F_G,Œµ_G,T,m_G) name attractor basins under those variables.
10) Active inference provides within‚Äëblanket dynamics; EFE supplies epistemic exploration pressure.
11) Finite structure + interface + energy bound which goals are feasible (CLC bound).
12) Failure beyond tolerance triggers exploration (Œµ‚Äëtrigger).
13) Exploration escalates by substrate cost: tune params ‚Üí retarget basin ‚Üí expand boundary ‚Üí reorganize scales.
14) Candidate changes are evaluated by expected success + information gain ‚àí implementation cost.
15) Successful changes are cached as reusable subassemblies with ordered competency types.
16) Reuse frequency is the engineered analogue of "copy number."
17) Caching expands feasible partitions and horizons, broadens causal profiles, compresses communication, and raises Œ∑.
18) Therefore: agents grow by failing, in a measurable, multiscale, thermodynamically constrained way.

---

## References (core set)

- Cronin, L., Walker, S.I., Sharma, A. et al. (2023). Assembly Theory and the origin of life. *Nature* 622, 553‚Äì563.
- Durant, F., Morokuma, J., Fields, C., Williams, K., Adams, D.S., Levin, M. (2017). Long-term stochastic editing of regenerative anatomy via targeting endogenous bioelectric gradients. *Biophys. J.* 112(10), 2231‚Äì2243.
- Emmons-Bell, M., Durant, F., Hammelman, J., et al. (2015). Gap junctional blockade stochastically induces different species-specific head anatomies in genetically wild-type *G. dorotocephala*. *IJMS* 16(11), 27865‚Äì27896.
- Fields, C., Levin, M. (2022). Competency in navigating arbitrary spaces as an invariant for analyzing cognition in diverse embodiments. *Entropy* 24(6), 819.
- Friston, K. (2010). The free-energy principle: a unified brain theory? *Nat. Rev. Neurosci.* 11, 127‚Äì138.
- Friston, K., Levin, M., Sengupta, B., Pezzulo, G. (2015). Knowing one's place: a free-energy approach to pattern regulation. *J. R. Soc. Interface* 12, 20141383.
- Friston, K., Schwartenbeck, P., FitzGerald, T., et al. (2012). The anatomy of choice: dopamine and decision-making. *Phil. Trans. R. Soc. B* 369, 20130481.
- Hoel, E.P., Albantakis, L., Tononi, G. (2013). Quantifying causal emergence shows that macro can beat micro. *PNAS* 110(49), 19790‚Äì19795.
- Hoel, E.P. (2017). When the map is better than the territory. *Entropy* 19(5), 188.
- Hoel, E.P. (2025). Causal Emergence 2.0. *arXiv*:2503.13395v3.
- Kirchhoff, M., Parr, T., Palacios, E., Friston, K., Kiverstein, J. (2018). The Markov blankets of life. *J. R. Soc. Interface* 15, 20170792.
- Kuchling, F., Friston, K., Georgiev, G., Levin, M. (2022). Morphogenesis as Bayesian inference. *Front. Comput. Neurosci.* 16, 988977.
- Levin, M. (2019). The computational boundary of a "Self". *Front. Psychol.* 10, 2688.
- Bruineberg, J., Dolega, K., Dewhurst, J., Baltieri, M. (2020). The Emperor's New Markov Blankets. *BBS*.

---

## v4 ‚Üí v5 change log

| # | Issue | Resolution |
|---|---|---|
| A | S_eff threshold œÑ discretizes continuous CP(l) | Added engineering‚Äëapproximation note acknowledging œÑ as practical necessity; noted CP‚Äëweighting alternative |
| B | VFE equation glossed factorization assumption | Simplified to single form (surprise + KL); added "under the standard generative model p(s,x) = p(s\|x)p(x)" |
| C | APS tier ordering unjustified | Added ordering rationale column to APS table + justification paragraph + diagnostic cascade questions |
| D | Competency taxonomy absent | Restored full taxonomy table in Proposition 7 with ordinal costs and landscape modifications |
| E | G‚Å∞‚ÜíG¬π formalization gap underutilized | Integrated into Goal Measurement Formalism definition + Tier 1 description + Open Problem 7 + Instrumentation |
| F | Missing Hoel 2025 CE 2.0 reference | Added to references and to CE 2.0 definition |
| G | Spec gap estimator vague | Replaced with "regret: expected failure rate minus Œµ_G from holdout episodes with distribution shift" |
| ‚Äî | One‚Äëline compression said "CP‚Äëweighted" but argument uses œÑ‚Äëthreshold | Changed to "CP‚Äëprofiled" |
| ‚Äî | CLC defined as max horizon only | Changed to max (T, dim(m_G)) ‚Äî spatiotemporal per Levin |
| ‚Äî | "Morphogenetic" absent after title | Added Scope section paragraph + Proposition 3 framing as morphogenetic instance |
| ‚Äî | Competency distribution missing from Proposition 8 predictions | Added as prediction 6 |
| ‚Äî | Formalization gap missing from instrumentation | Added row |
| ‚Äî | Competency ‚Üí ŒîAI derivation missing from open problems | Added as Open Problem 6 |
